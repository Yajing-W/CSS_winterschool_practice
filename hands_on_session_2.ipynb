{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Session 2: Longitudinal Behavioral Analysis & Mental Health (LMM)\n",
        "\n",
        "In this session, we will link people's high-frequency digital traces with their psychological well-being. BWe will analyze how web browsing patterns correlate with **Loneliness (UCLA-3)** and **Stress (PSS-10)** using a dataset covering 50 individuals over 6 months.\n",
        "\n",
        "To account for the **longitudinal and nested structure** of this data (repeated observations within individuals), we will implement **Linear Mixed-Effects Models (LMM)**.\n",
        "\n",
        "### What we will do?\n",
        "* **Perform Data Alignment**: Merge datasets with different temporal resolutions (e.g., second-level logs vs. monthly surveys).\n",
        "* **Execute Feature Engineering**: Calculate online behavioral features such as diurnal activity patterns (Day vs. Night) and category-specific engagement.\n",
        "* **Implement Mixed-Effects Modeling**: Understand the practical distinction between **Fixed Effects** (population-level trends) and **Random Effects** (individual variations).\n",
        "\n",
        "\n",
        "### Pre-reading & Resources on LMM\n",
        "If you need a refresher on Linear Mixed Models, please refer to:\n",
        "* **The \"Plain English\" Guide**: [Introduction to Mixed Effects Models](https://ourcodingclub.github.io/tutorials/mixed-models/) (Coding Club)\n",
        "* **The Academic Reference**: Meteyard, L., & Davies, R. A. (2020). [Best practice guidance for linear mixed-effects models in psychological science](https://pmc.ncbi.nlm.nih.gov/articles/PMC7153721/). *Journal of Memory and Language*.\n",
        "* **Documentation**: [Statsmodels LMM Overview](https://www.statsmodels.org/stable/mixed_linear.html) - *Technical documentation for the library we will use today.*"
      ],
      "metadata": {
        "id": "_Ap5IlSO3cWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Programming Toolkit\n",
        "\n",
        "To perform this analysis, we will use several specialized Python libraries. You can refer to the official documentation for detailed API information:\n",
        "\n",
        "| Library | Category | Purpose | Documentation |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **Pandas** | Data Manipulation | Handling dataframes, time-series alignment, and merging. | [Link](https://pandas.pydata.org/docs/) |\n",
        "| **NumPy** | Numerical Computing | Vectorized operations and mathematical functions. | [Link](https://numpy.org/doc/) |\n",
        "| **Statsmodels** | Statistical Modeling | Implementing Linear Mixed-Effects Models (LMM) and summary stats. | [Link](https://www.statsmodels.org/stable/index.html) |\n",
        "| **Seaborn** | Data Visualization | Drawing statistical graphics. | [Link](https://seaborn.pydata.org/) |\n",
        "| **Matplotlib** | Plotting Engine | Base library for plot aesthetics and layouts. | [Link](https://matplotlib.org/stable/index.html) |\n",
        "| **Scipy** | Scientific Computing | Used for statistical tests and probability distributions. | [Link](https://docs.scipy.org/doc/scipy/) |\n",
        "\n",
        ">Run the code cell below to initialize your environment."
      ],
      "metadata": {
        "id": "YpGtLw7rddDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.formula.api as smf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for cleaner output during the lab\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- Visualization Settings ---\n",
        "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
        "plt.rcParams.update({\n",
        "    'figure.figsize': (10, 6),\n",
        "    'axes.titlesize': 14,\n",
        "    'axes.labelsize': 12,\n",
        "    'xtick.labelsize': 10,\n",
        "    'ytick.labelsize': 10\n",
        "})"
      ],
      "metadata": {
        "id": "irkeNwJu3vxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Acquisition & Structural Overview\n",
        "\n",
        "In this session, we work with four datasets. Our goal is to align these into a single \"longitudinal\" dataframe ready for modeling.\n",
        "\n",
        "### 2.1 Dataset Descriptions\n",
        "\n",
        "| Dataset | Granularity | Key Columns | Description |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **Browsing Logs** | High-frequency | `pid`, `used_at`,`domain`, `duration`, `wave` | Raw web traces recording every URL visited. |\n",
        "| **Surveys** | Monthly (6 waves) | `pid`, `wave`, `ucla_3`, `pss_10` | Repeated mental health assessments. |\n",
        "| **Demographics** | Static | `pid`, `gender`, `age_group` | Constant user characteristics. |\n",
        "| **Domain Map** | Metadata | `domain`, `category` | Mapping URLs to functional categories (e.g., Social, News). |\n",
        "\n",
        "### 2.2 Variables of Interest\n",
        "\n",
        "#### **Mental Health Indicators (Dependent Variables)**\n",
        "* **UCLA-3 (Loneliness)**: A 3-item scale measuring feelings of social isolation.\n",
        "    * **Range**: 3 to 9. Higher scores indicate **greater loneliness**.\n",
        "* **PSS-10 (Perceived Stress)**: A 10-item scale measuring the degree to which situations in life are appraised as stressful.\n",
        "    * **Range**: 0 to 40. Higher scores indicate **higher perceived stress**.\n",
        "\n",
        "#### **Demographic Coding**\n",
        "* **Gender**: `1` = Male, `0` = Female.\n",
        "* **Age Group**:\n",
        "    * `1`: 18 – 30 years old\n",
        "    * `2`: 31 – 60 years old\n",
        "    * `3`: 60+ years old\n"
      ],
      "metadata": {
        "id": "pEDfoIA730vM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data Loading ---\n",
        "BASE_URL = \"https://raw.githubusercontent.com/Yajing-W/CSS_winterschool_practice/refs/heads/main/\"\n",
        "\n",
        "# Load the datasets from the remote repository\n",
        "try:\n",
        "    df_logs = pd.read_parquet(BASE_URL + \"browsing_traces_waves.parquet\")\n",
        "    df_survey = pd.read_csv(BASE_URL + \"surveys.csv\")\n",
        "    df_demo = pd.read_csv(BASE_URL + \"demographics_session_2.csv\")\n",
        "    df_domain_map = pd.read_csv(BASE_URL + \"domain_category_map.csv\")\n",
        "\n",
        "    print(\"All datasets loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {e}\")\n",
        "\n",
        "\n",
        "print(f\"\\n[Summary Statistics]\")\n",
        "print(f\"- Browser Logs: {df_logs.shape[0]} records\")\n",
        "print(f\"- Survey Responses: {df_survey.shape[0]} records\")\n",
        "print(f\"- Demographic Profiles: {df_demo.shape[0]} users\")\n",
        "\n",
        "print(f\"\\n[Preview: Demographics (df_demo)]\")\n",
        "display(df_demo.head())\n",
        "\n",
        "print(f\"\\n[Preview: Browser Logs (df_logs)]\")\n",
        "display(df_logs.head())"
      ],
      "metadata": {
        "id": "mYP_OtAo4v_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Feature Engineering: Defining Behavioral Markers\n",
        "\n",
        "To find the association with mental health, we need to convert raw timestamped logs into meaningful behavioral indicators. For each user (`pid`) within each measurement period (`wave`), we will extract the following features:\n",
        "\n",
        "| Feature | Definition | Behavioral Significance |\n",
        "| :--- | :--- | :--- |\n",
        "| **Total_Duration** | Total monthly online hours. | Overall digital engagement behavior. |\n",
        "| **Daily_avg_duration** | Average daily online hours. | Daily intensity of digital usage. |\n",
        "| **Day_Night_Diff** | (Duration 06:00-18:00) - (Duration 18:00-06:00). | Negative values indicate high nocturnal activity, often linked to sleep disruption and stress. |\n",
        "| **Category_Hours** | Total hours spent on 'Social Media', 'Games', 'Shopping' and etc. | Distinguishes between communication, entertainment-seeking, and impulsive behaviors. |\n",
        "\n",
        "\n",
        "\n",
        "> **Note on Scaling**: We convert the raw `duration` (seconds) into **Hours** to ensure our regression coefficients ($\\beta$) are interpretable (e.g., \"an increase of 1 hour is associated with X points of stress\").\n",
        "\n",
        "> Calculate these features and aggregate them at the `(pid, wave)` level."
      ],
      "metadata": {
        "id": "noXg2CH65Rmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract behavioral features from browser logs\n",
        "\n",
        "# We merge logs with the domain map to identify the type of activity\n",
        "df_logs_mapped = pd.merge(df_logs, df_domain_map, on=...., how=...)\n",
        "# Assign 'uncategorized' to any domain not found in our mapping table\n",
        "df_logs_mapped['category'] = df_logs_mapped['category'].fillna('uncategorized')\n",
        "\n",
        "#Temporal Processing\n",
        "df_logs_mapped['used_at'] = pd.to_datetime(df_logs_mapped['used_at'])\n",
        "df_logs_mapped['hour'] = df_logs_mapped['used_at'].dt.hour\n",
        "df_logs_mapped['is_daytime'] = df_logs_mapped['hour'].between(6, 17) # Day: 06:00-17:59\n",
        "\n",
        "# Convert seconds to hours for better scale in modeling\n",
        "total_dur = df_logs_mapped.groupby(['pid', 'wave'])['duration'].sum() / 3600\n",
        "\n",
        "# Day-Night Duration Difference\n",
        "day_night = df_logs_mapped.pivot_table(index=['pid', 'wave'],\n",
        "                                       columns='is_daytime',\n",
        "                                       values='duration',\n",
        "                                       aggfunc='sum',\n",
        "                                       fill_value=0) / 3600\n",
        "day_night_diff = day_night.get(True, 0) - day_night.get(False, 0)\n",
        "\n",
        "# We group by pid/wave/category and pivot to get hours per category\n",
        "cat_hours = df_logs_mapped.groupby(['pid', 'wave', 'category'])['duration'].sum().unstack(fill_value=0) / 3600\n",
        "\n",
        "# Construct Feature Dataframe\n",
        "df_features = pd.DataFrame({\n",
        "    'total_duration': total_dur,\n",
        "    'day_night_diff': day_night_diff,\n",
        "    'social_media_duration': cat_hours.get('social_media', 0),\n",
        "    'games_duration': cat_hours.get('games', 0),\n",
        "    'shopping_duration': cat_hours.get('shopping', 0)\n",
        "}).reset_index()\n",
        "\n",
        "df_features['daily_avg_duration'] = df_features['total_duration'] / 28\n",
        "display(df_features.head())"
      ],
      "metadata": {
        "id": "IJWTeKvl5ivP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Data Integration: Building the Longitudinal Dataset\n",
        "\n",
        "Now that we have extracted behavioral markers from raw logs, we must align them with our mental health labels (Survey scores) and user characteristics (Demographics).\n",
        "\n",
        "### The Merging Logic\n",
        "To perform a **Linear Mixed-Effects (LMM)** analysis, our data must be in **Long Format**. This means:\n",
        "1.  **Time-Varying Data**: Behavioral features and Survey scores are matched by both User ID (`pid`) and Time (`wave`).\n",
        "2.  **Static Data**: Demographic info (Gender, Age) is matched only by User ID (`pid`) and is repeated for every wave of that user.\n",
        "\n",
        "\n",
        "\n",
        "### Handling Missingness\n",
        "Unlike traditional OLS or ANOVA, LMM does not require every participant to have data for every single wave.\n",
        "However, we still need to ensure that for any given \"User-Wave\" observation, we have both the predictor (behavior) and the outcome (survey score).\n",
        "* We use an **Inner Join** between surveys and behavior to ensure our model only trains on complete observations (Timepoints where we have both a behavioral \"predictor\" and a mental health \"outcome\").\n",
        "\n",
        "\n",
        "> 1. Check for missing values in the survey dataset.\n",
        "> 2. Consolidate the data into a single long-format dataframe."
      ],
      "metadata": {
        "id": "99fO6tgppWDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in Survey data ---\n",
        "print(\"Checking for missing values in Surveys:\")\n",
        "print(df_survey[['ucla_3', 'pss_10']].isnull().sum())\n",
        "\n",
        "#use 'inner' join here because a model needs both X (behavior) and Y (survey)\n",
        "# Merge with Demographics\n",
        "df_final = .....\n",
        "\n",
        "\n",
        "\n",
        "n_original_users = df_survey['pid'].nunique()\n",
        "n_final_users = df_final['pid'].nunique()\n",
        "print(f\"\\nOriginally: {n_original_users} users.\")\n",
        "print(f\"After merging: {n_final_users} users retained.\")\n",
        "print(f\"Total User-Wave observations for LMM: {len(df_final)}\")\n",
        "\n",
        "# Sort for longitudinal structure\n",
        "df_final = df_final.sort_values(['pid', 'wave']).reset_index(drop=True)\n",
        "display(df_final.head())"
      ],
      "metadata": {
        "id": "k3ir5CPtpMla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Pre-modeling Diagnostics\n",
        "\n",
        "Before fitting our Linear Mixed-Effects Models (LMM), we must evaluate the relationships between our predictors.\n",
        "\n",
        "### 4.1 Multicollinearity: Correlation & VIF (add some ref about this)\n",
        "In behavioral research, different metrics often carry redundant information. We use two complementary tools to detect **Multicollinearity**:\n",
        "1.  **Correlation Matrix (Qualitative)**: A heatmap showing pairwise relationships. We look for coefficients $|r| > 0.7$.\n",
        "2.  **Variance Inflation Factor (VIF, Quantitative)**: Measures how much a variable is explained by *all other* predictors combined.\n",
        "    * **VIF < 5**: Generally acceptable.\n",
        "    * **VIF > 10**: Indicates high multicollinearity; the variable may need to be removed to ensure model stability.\n",
        "\n",
        "### 4.2 Categorical Factor Conversion\n",
        "We ensure `gender` and `age_group` are treated as **factors**. This allows the model to estimate differences between groups (e.g., comparing Age Group 1 vs. Group 2) rather than treating them as continuous numbers.\n",
        "\n",
        "> **Task**:\n",
        "> 1. Compute and visualize the correlation matrix for behavioral features.\n",
        "> 2. Calculate the VIF for our behavioral markers.\n",
        "> 3. Convert demographic variables into the proper categorical format.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nKUxVhJi7Atb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Variable Selection\n",
        "behavioral_cols = [\n",
        "    'total_duration', 'daily_avg_duration',\t'day_night_diff', 'social_media_duration',\n",
        "    'games_duration', 'shopping_duration'\n",
        "]\n",
        "\n",
        "# Categorical Factor Conversion\n",
        "df_model = df_final.copy()\n",
        "df_model['gender'] = df_model['gender'].astype('category')\n",
        "df_model['age_group'] = df_model['age_group'].astype('category')\n",
        "\n",
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(10, 7))\n",
        "corr_matrix = df_model[behavioral_cols].corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0, fmt=\".2f\", vmin=-1, vmax=1)\n",
        "plt.title(\"Correlation Matrix: Behavioral Predictors\")\n",
        "plt.show()\n",
        "\n",
        "# VIF Calculation\n",
        "# We add a constant as VIF requires an intercept to be mathematically sound\n",
        "X_vif = df_model[behavioral_cols].assign(const=1)\n",
        "\n",
        "vif_df = pd.DataFrame()\n",
        "vif_df[\"Feature\"] = X_vif.columns\n",
        "vif_df[\"VIF\"] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
        "\n",
        "print(\"\\n[VIF Diagnostics Table]\")\n",
        "# We exclude the 'const' row for the final display\n",
        "display(vif_df[vif_df['Feature'] != 'const'].round(2).sort_values(by=\"VIF\", ascending=False))\n",
        "\n"
      ],
      "metadata": {
        "id": "XQJlDtEO7Jvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_model = df_model.drop(columns=['daily_avg_duration'])\n",
        "behavioral_cols = [\n",
        "    'total_duration',\t'day_night_diff', 'social_media_duration',\n",
        "    'games_duration', 'shopping_duration'\n",
        "]\n",
        "\n",
        "# 5. Final Data Integrity Check\n",
        "print(\"\\n[Descriptive Statistics: Behavioral Metrics (Hours)]\")\n",
        "display(df_model[behavioral_cols].describe().round(2))"
      ],
      "metadata": {
        "id": "6HaEptupnLrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Feature Transformation: To Scale or Not to Scale?\n",
        "\n",
        "In this lab, we have chosen to keep our behavioral predictors in their **raw units (hours)** to ensure that our coefficients ($\\beta$) have a direct physical interpretation (e.g., \"one extra hour of gaming leads to $X$ points change in stress\"). However, this choice involves a trade-off regarding **Model Convergence**.\n",
        "\n",
        "Unlike simple OLS regression, LMMs are estimated using iterative numerical algorithms (such as **Restricted Maximum Likelihood - REML**). The algorithm \"searches\" for the best parameters that maximize the likelihood of the data.\n",
        "* **The Convergence Risk**: If our predictors have vastly different scales (e.g., one variable ranges from 0.1 to 1.0, while another ranges from 10 to 500), the optimization surface becomes very \"steep\" in some directions and \"flat\" in others. This can cause the algorithm to fail, resulting in a **\"Convergence Warning\"** or a **\"Singular Fit\"**.\n",
        "* **Standardization as a Solution**: Standardizing variables (Z-score) ensures all predictors have a mean of 0 and a standard deviation of 1. This \"round\" optimization space makes it much easier for the algorithm to reach the global optimum.\n",
        "\n",
        "> **Instruction**: We will proceed with raw hours. If you encounter a `ConvergenceWarning` or `Singular Matrix` error in the next step, the first troubleshooting step should be returning here to standardize your features."
      ],
      "metadata": {
        "id": "6iYaP2YSszz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Linear Mixed-Effects Modeling (LMM)\n",
        "\n",
        "In this section, we move beyond simple correlation to **statistical modeling**. Our data has a nested structure: multiple observations (Waves) are clustered within individuals (`pid`).\n",
        "\n",
        "### 5.1 Why use LMM?\n",
        "A standard linear regression (OLS) assumes all observations are independent. However, a person's loneliness score at Wave 2 is likely related to their score at Wave 1. LMM accounts for this by splitting the model into:\n",
        "1.  **Fixed Effects**: The average relationship between digital behavior and mental health across the whole population.\n",
        "2.  **Random Effects**: The individual \"baseline\" differences. Some people are naturally more lonely or stressed than others.\n",
        "\n",
        "### 5.2 Model Specification\n",
        "We use the following formula for both models:\n",
        "$$MentalHealth_{ij} = (\\beta_0 + u_i) + \\beta_1(Behavior_{ij}) + \\beta_2(Demographics_i) + \\epsilon_{ij}$$\n",
        "\n",
        "Where:\n",
        "* $u_i$ is the **Random Intercept** for person $i$ (capturing individual stability).\n",
        "* $\\beta$ are the **Fixed Effects** (the universal trends we want to discover).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 5.3 Modeling Loneliness (UCLA-3)\n",
        "\n",
        "In this step, we evaluate not just the coefficients, but also the **Model Performance**:\n",
        "* **ICC (Intraclass Correlation Coefficient)**: Proportion of variance explained by individual differences.\n",
        "> ***Rule of Thumb**: If **$ICC > 0.05$**, it indicates that the nested structure of the data is significant, and using an LMM is mandatory to avoid biased results.*\n",
        "* **Marginal $R^2$**: Variance explained by our behavioral predictors (Fixed Effects).\n",
        "* **Conditional $R^2$**: Total variance explained by the entire model (Fixed + Random Effects).\n",
        "\n",
        "> **Task**: Fit the Loneliness model and calculate these model performance index."
      ],
      "metadata": {
        "id": "cycJvPqq5rcO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<mark>**Question 1**: Is loneliness related to total online time?"
      ],
      "metadata": {
        "id": "ZR7BtLRdCJK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_mixed_model(df, formula, group_col='pid'):\n",
        "    \"\"\"\n",
        "    Fits a Linear Mixed-Effects Model and attaches ICC, Marginal R2,\n",
        "    and Conditional R2 as attributes to the returned model object.\n",
        "    \"\"\"\n",
        "    # 1. Fit the Model\n",
        "    model = smf.mixedlm(formula, df, groups=df[group_col]).fit()\n",
        "\n",
        "    # 2. Extract Variance Components\n",
        "    # var_random: Intercept variance (Between-person)\n",
        "    # var_resid: Residual variance (Within-person / Error)\n",
        "    var_random = model.cov_re.iloc[0, 0]\n",
        "    var_resid = model.scale\n",
        "\n",
        "    # 3. Calculate Fixed Effects Variance\n",
        "    fixed_preds = model.predict(df)\n",
        "    var_fixed = fixed_preds.var()\n",
        "\n",
        "    # 4. Calculate Metrics\n",
        "    total_var = var_fixed + var_random + var_resid\n",
        "\n",
        "    # Attach as attributes to the model object\n",
        "    model.icc = var_random / (var_random + var_resid)\n",
        "    model.marginal_r2 = var_fixed / total_var\n",
        "    model.conditional_r2 = (var_fixed + var_random) / total_var\n",
        "\n",
        "    # 5. Print Summary Table\n",
        "    print(\"\\n\" + \"=\"*45)\n",
        "    print(f\"{'MIXED MODEL DIAGNOSTICS':^45}\")\n",
        "    print(\"-\" * 45)\n",
        "    print(f\"Marginal R2 (Fixed Effects):    {model.marginal_r2:.4f}\")\n",
        "    print(f\"Conditional R2 (Total Model):   {model.conditional_r2:.4f}\")\n",
        "    print(f\"ICC (Individual Level):         {model.icc:.4f}\")\n",
        "    print(\"=\"*45 + \"\\n\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "H52OS8v0rV6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formula = \"ucla_3 ~ total_duration + gender + age_group\"\n",
        "model_1 = fit_mixed_model(df_model, formula )\n",
        "print(model_1.summary())"
      ],
      "metadata": {
        "id": "Y009kP3hroSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Project: Behavioral Traces & Well-being\n",
        "\n",
        "\n",
        "Discover new insights from the digital trace data.\n",
        "\n",
        "### Selection:\n",
        "* **Question**: Are you predicting **Stress** (`pss_10`) or **Loneliness** (`ucla_3`)?\n",
        "* **Hypothesis**: Which behavior do you think matters?\n",
        "    * *Option A*: Use existing features (`day_night_diff`, `social_media_duration`, etc.).\n",
        "    * *Option B*: Go back to **Section 3.1** and define a new feature.\n",
        "* **Check for Issues**: If you use multiple behavioral features, reuse the **correlation & VIF code** to check for multi-collinearity.\n",
        "\n",
        "### Modeling & Analysis\n",
        "* Build at least **two different models** to compare.\n",
        "* Sub-group Analysis: Does your hypothesis hold for everyone? Try filtering the data:\n",
        "    ```python\n",
        "    # Example: Running the model only for the 'Younger' group (age_group == 1)\n",
        "    df_young = df_model[df_model['age_group'] == 1]\n",
        "    model_young = smf.mixedlm(\"pss_10 ~ social_media_duration\", df_young, groups=df_young[\"pid\"]).fit()\n",
        "    ```\n",
        "\n",
        "### Share results\n",
        "* Use the `plot_effect_comparison` function to visualize your models.\n",
        "* **what** the coefficients tell us."
      ],
      "metadata": {
        "id": "iu29crQsrv6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing Model Findings: Effect Size Comparison\n",
        "\n",
        "In the final step of our analysis, we will visualize the **Fixed Effects** from our LMMs.\n",
        "### Interpreting the Plot\n",
        "* **X-axis (Coefficient)**: Represents the change in mental health score for every **1-hour increase** in behavior.\n",
        "* **Positive Values**: The behavior is associated with *increased* loneliness/stress.\n",
        "* **Vertical Line at 0**: If the error bar crosses this line, the effect is likely not statistically significant.\n"
      ],
      "metadata": {
        "id": "dKnGLIbKzMb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# WORKSPACE\n",
        "# ==========================================\n",
        "\n",
        "#-----Define and fit your models-----\n",
        "# model_a = fit_mixed_model(df, formula, group_col='pid')\n",
        "# model_b = fit_mixed_model(df, formula, group_col='pid')\n",
        "\n",
        "#print(model_a.summary())"
      ],
      "metadata": {
        "id": "n2SlTZcfshIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_behavioral_comparison(model_dict, behavioral_features=None):\n",
        "    \"\"\"\n",
        "    Plots a grouped bar chart for multiple models with significance stars.\n",
        "\n",
        "    Args:\n",
        "        model_dict (dict): Format {'Display Name': model_object}\n",
        "        behavioral_features (list): List of predictor names to include in the plot.\n",
        "    \"\"\"\n",
        "\n",
        "    # Default feature list if none provided\n",
        "    if behavioral_features is None:\n",
        "        behavioral_features = ['social_media_duration', 'games_duration', 'shopping_duration', 'day_night_diff']\n",
        "\n",
        "    # 1. Consolidate results using the dictionary keys as 'Model' labels\n",
        "    all_results = []\n",
        "    for label, model_obj in model_dict.items():\n",
        "        temp_df = pd.DataFrame({\n",
        "            'Predictor': model_obj.params.index,\n",
        "            'Coefficient': model_obj.params.values,\n",
        "            'p_value': model_obj.pvalues.values,\n",
        "            'Model': label\n",
        "        })\n",
        "        # Filter only for the features we care about\n",
        "        temp_df = temp_df[temp_df['Predictor'].isin(behavioral_features)].copy()\n",
        "        all_results.append(temp_df)\n",
        "\n",
        "    results = pd.concat(all_results).reset_index(drop=True)\n",
        "\n",
        "    # 2. Dynamic Plot Sizing\n",
        "    # Adjust height based on number of models and predictors\n",
        "    num_models = len(model_dict)\n",
        "    num_vars = len(behavioral_features)\n",
        "    plt.figure(figsize=(14, max(6, num_vars * num_models * 0.5)))\n",
        "\n",
        "    # 3. Initialize the plotting area\n",
        "    # Use 'order' to ensure the Y-axis follows your input list exactly\n",
        "    ax = sns.barplot(\n",
        "        data=results,\n",
        "        x='Coefficient',\n",
        "        y='Predictor',\n",
        "        hue='Model',\n",
        "        palette=\"RdYlBu\",\n",
        "        order=behavioral_features\n",
        "    )\n",
        "\n",
        "    # 4. Add Significance Stars (*)\n",
        "    # We iterate through containers (one for each model/hue)\n",
        "    for i, container in enumerate(ax.containers):\n",
        "        # Get the label for the current hue group\n",
        "        model_name = list(model_dict.keys())[i]\n",
        "        subset = results[results['Model'] == model_name].set_index('Predictor')\n",
        "\n",
        "        # Annotate each bar in the current container\n",
        "        for j, bar in enumerate(container):\n",
        "            # Map bar back to predictor via the fixed Y-axis order\n",
        "            predictor_name = behavioral_features[j]\n",
        "\n",
        "            if predictor_name in subset.index:\n",
        "                p_val = subset.loc[predictor_name, 'p_value']\n",
        "\n",
        "                if p_val < 0.05:\n",
        "                    width = bar.get_width()\n",
        "                    y_pos = bar.get_y() + bar.get_height() / 2\n",
        "\n",
        "                    # Strategic offset: 1% of the x-axis range\n",
        "                    x_range = ax.get_xlim()[1] - ax.get_xlim()[0]\n",
        "                    offset = 0.01 * x_range if width >= 0 else -0.01 * x_range\n",
        "\n",
        "                    ax.text(\n",
        "                        width + offset, y_pos, '*',\n",
        "                        ha='center', va='center',\n",
        "                        fontsize=20, color='black', fontweight='bold'\n",
        "                    )\n",
        "\n",
        "    # 5. Aesthetics and Labeling\n",
        "    plt.axvline(0, color='black', linestyle='-', linewidth=1.5, alpha=0.5)\n",
        "    plt.title(\"Impact of Digital Behaviors on Mental Health\\n(Stars * indicate p < 0.05)\", fontsize=16, pad=20)\n",
        "    plt.xlabel(\"Effect Size (Coefficient Beta)\", fontsize=12)\n",
        "    plt.ylabel(\"Digital Behavior Predictors\", fontsize=12)\n",
        "\n",
        "    # Place legend outside\n",
        "    plt.legend(title=\"Model / Group\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(axis='x', linestyle=':', alpha=0.6)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "n07z5cX99nN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- Effect Size Comparison\n",
        "# features will included\n",
        "my_features = [\n",
        "    'total_duration',\n",
        "]\n",
        "\n",
        "# 2.  models in a dictionary (supports 2 to 8 models)\n",
        "my_models = {\n",
        "    'Loneliness (Total)': model_1,\n",
        "}\n",
        "\n",
        "# 3. Run the function\n",
        "plot_behavioral_comparison(my_models, behavioral_features=my_features)"
      ],
      "metadata": {
        "id": "NRruRL9D-HZl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}